# ğŸ”¥ Safety Equipment Detection Using YOLO (7-Class Model)
### **Team: Byte_Coders**
**Members:**  
- **Shinjan Saha**  
- **Satyabrata Das Adhikari**  
- **Sayan Sk**

This project was developed for the **Duality AI/ML Challenge** as part of the **Cosmohack1 Hackathon**.  
The goal is to detect critical safety equipment (Oxygen Tanks, Fire Alarms, Fire Extinguishers, First Aid Boxes, etc.) using a YOLO-based model trained on a 7-class dataset provided by Duality.

---

# ğŸ“Œ 1. Project Overview
This repository contains the full pipeline for training, evaluating, and running predictions using a YOLOv8 model.  
The system is robust to:

- Occlusion  
- Poor lighting  
- Cluttered industrial environments  

The model outputs bounding boxes, class labels, and confidence scores for **7 object categories**.

---

# âš™ï¸ 2. Environment Setup

### **Recommended Python Version**
Python 3.8 â€“ 3.10
(âš ï¸ YOLOv8 does not support Python 3.12 yet)

### **Install Dependencies**
`pip install -r requirements.txt`

Typical requirements include:
- flask
- flask-cors
- ultralytics
- opencv-python
- torch
- torchvision
- numpy
- Pillow

---

# ğŸ” 3. How to Reproduce Final Results

## **Step 1 â€” Download the Dataset**
Download the training + validation + test datasets from:  ğŸ”—[Dataset link](https://falcon.duality.ai/secure/documentation/7-class-hackathon&utm_source=hackathon&utm_medium=instructions&utm_campaign=cosmohack1)

Place the datasets in the **root folder** of the project.

Example structure:
```
project/
â”œâ”€â”€ train_2/
â”‚ â”œâ”€â”€ train2/images
â”‚ â”œâ”€â”€ train2/labels
â”‚ â”œâ”€â”€ val2/images
â”‚ â””â”€â”€val2/labels
â”œâ”€â”€ test1/
â”‚ â”œâ”€â”€ images
â”‚ â””â”€â”€labels
â”œâ”€â”€ yolo_params.yaml
```

---

## **Step 2 â€” Update `yolo_params.yaml` Paths**
```
train: train_2/train2/images
val: train_2/val2/images
test: test1/images
```

These augmentations replicate our final training setup for improved robustness.

## **Step 3 â€” Train the Model (40 Epochs)**

Run the custom `train.py` script:

`python train.py --epochs 40`

Our training script uses:
- YOLOv8s
- Image size 832
- Batch size 4
- Mosaic augmentation (0.4)
- AdamW optimizer
- Learning rate 1e-4

## **Step 4 â€” View Training Results**
YOLO automatically creates training outputs in:

runs/detect/train/
Inside this folder, you will find:

ğŸ“Š Graphs
results.png (loss curves, precision, recall, mAP)
```
BoxF1_curve.png
BoxPR_curve.png
BoxP_curve.png
BoxR_curve.png
results.csv
```

ğŸ§  Model Weights
```
best.pt
last.pt
```

## **Step 5 â€” Run Single Image Prediction**
Edit the paths in `predict.py`:
```
MODEL_PATH = "runs/detect/train/weights/best.pt"
IMAGE_PATH = "test1/images/000000007_dark_clutter.png"
OUTPUT_DIR = "predictions"
CONFIDENCE = 0.5
```
Run:
`python predict.py`

Outputs will be saved in:
```
predictions/images/
predictions/labels/
```

Example console output:
```
Detected 4 objects:
 - OxygenTank (96%)
 - FireAlarm (92%)
 - NitrogenTank (88%)
 - FireExtinguisher (90%)
```

---

# ğŸš€ 4. Testing the Model on the Full Test Set `predict2.py`
Run the automated batch-testing script: `python predict2.py`

This script:
- Auto-detects the correct best.pt
- Reads the test path from yolo_params.yaml
- Runs inference on every image in test1/images
- Saves outputs to:
```
predictions2/images/
predictions2/labels/
```
Example output:
```
âœ“ 000000314.png: Detected 3 objects
âœ“ 000000315.png: No objects detected
.
.
.
============================================================
PREDICTION COMPLETE
============================================================
âœ“ Processed 300 image(s)
âœ“ Annotated images saved in: predictions2/images
âœ“ Labels saved in: predictions2/labels
```

If `RUN_VALIDATION = True`, the script automatically runs:

`model.val(data=yolo_params.yaml, split="test")`

This prints:
- mAP50
- mAP50-95
- Precision
- Recall
- Confusion matrix


---

# ğŸ“ 5. Project Structure
```
â”œâ”€â”€ train.py
â”œâ”€â”€ predict.py
â”œâ”€â”€ predict2.py
â”œâ”€â”€ yolo_params.yaml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ runs/
â”œâ”€â”€ predictions/
â”œâ”€â”€ predictions2/
â”œâ”€â”€ train_2/
â”œâ”€â”€ test1/
â””â”€â”€ README.md
```

---

# ğŸ“¤ 6. Expected Outputs & Interpretation
Annotated Predictions (Images) saved to:
```
predictions/images/
predictions2/images/
```

Each image contains:

âœ”ï¸ Bounding boxes

âœ”ï¸ Class labels

âœ”ï¸ Confidence values

âœ”ï¸ YOLO Label Files

Saved to:
```
predictions/labels/
predictions2/labels/
```

Metric Files:
```
runs/detect/train*/results.csv
runs/detect/train*/results.png
```

Use these to interpret:
- Precision
- Recall
- mAP 50 and mAP 50-95
- Convergence behavior

---

# ğŸ“¬ Interested in a Similar Project?

I build smart, ML-integrated applications and responsive web platforms. Letâ€™s build something powerful together!

ğŸ“§ shinjansaha00@gmail.com

ğŸ”— [LinkedIn Profile](https://www.linkedin.com/in/shinjan-saha-1bb744319/)